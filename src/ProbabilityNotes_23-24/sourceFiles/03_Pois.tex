
\subsection{Poisson Distribution}

\ssn{Motivating problem}
\begin{itemize}
\item During busy times, calls arrive at a call centre at an average rate of 10 per minute.  What is the probability of four or more arriving in a period of twelve seconds?
\item Huge numbers of dust particles drift around in a large volume. On average, there are $10^6$ per cubic metre. How probable is it that at a certain moment, a cubic centimetre contains three or more particles. 
\end{itemize}
\end{n}

\ssn{A possible model}
For the call centre, if one expects 10 calls per minute, then one expects 2 calls in 12 seconds. One might imagine that those 2 calls arise because there are $n=1000$ customers, each independently with a probability $p=0.002$ of calling during that minute. Or possibly one has $n=10000$ and $p=0.0002$.   With either assumption, we could calculate probabilities with a binomial random variable. 

The problem is that we do not know the values of $n$ and $p$; we know only that the expected number of calls is $np=2$.  In this sort of situation, we really do not want an unknown large $n$ hanging around. Instead we take a limit as $n \map \infty$ keeping $np$ constant. 
\end{n}

\ssn{Taking the limit}
Suppose we fix $\lambda>0$ (where $\lambda=2$ in the example above). Set $p=\lambda/n$ so that the expected value of a binomial $(n,p)$ random variable $X$ is $np=\lambda$. Then 
 \begin{eqnarray*}
 \PP(X=k) &=& \binom{n}{k} p^k (1-p)^{n-k} = \binom{n}{k} 
      \left( \frac{\lambda}n \right)^k 
       \left( 1-\frac{\lambda}n \right)^{n-k}  \\ 
   &=& \frac{n!}{k! (n-k)!} \frac{\lambda^k}{n^k} 
      \left( 1-\frac{\lambda}n \right)^{-k} \left( 1-\frac{\lambda}n \right)^{n}  \\
      &=& \frac{\lambda^k}{k!} \; \underbrace{\frac{n(n-1)\dots(n-k+1)}{n^k}}_{\text{Limit = 1}} \;\;
      \underbrace{\left( 1-\frac{\lambda}n \right)^{-k}}_{\text{Limit = 1}} \;\;    
      \underbrace{ \left( 1-\frac{\lambda}n \right)^{n}}_{\text{Limit = $e^{-\lambda}$}}\\ 
   &\map& e^{-\lambda} \frac{\lambda^k}{k!} \qquad \text{as $n$ tends to infinity.}
 \end{eqnarray*}
 Of the three limits, the first can be seen by dividing top and bottom by $n^k$; the second is because $(1-\lambda/n) \map 1$ as $n\map\infty$ and $k$ is a fixed number; the last is a standard result. 
\end{n}

\ssn{Definition: Poisson distribution} \hfill 
\tcb 
A random variable $X$ on $\{0,1,2,\dots\}$ such that 
 \[
      \PP(X=k) = e^{-\lambda} \frac{\lambda^k}{k!}
  \]
is called a \emph{Poisson random variable with parameter $\lambda$}. 
\etcb 

\noindent 
We should check that this really does define a random variable, i.e.\ that the sum of all the probabilities is equal to one.  That is the case since 
\[
 \sum_0^\infty \PP(X=k) = e^{-\lambda} \sum_0^\infty \frac{\lambda^k}{k!} = e^{-\lambda}  e^\lambda = 1. 
\]
\end{n}

\ssn{Mean and variance}
Let's calculate the probability generating function of a Poisson RV with parameter $\lambda$.  
\[
  G_X(s) = \EE(s^X) = \sum_{k=0}^\infty e^{-\lambda} \frac{\lambda^k}{k!} s^k = e^{-\lambda} e^{\lambda s} = e^{\lambda(s-1)}. 
\]
Then $G_X'(s) = \lambda e^{\lambda(s-1)}$ and $G_X''(s) = \lambda^2 e^{\lambda(s-1)}$.   So 
 \[
  \EE(X) = G_X'(1) = \lambda, \qquad \var(X) = G_X''(1) + G_X'(1) 
    - \left( G_X'(1) \right)^2 = \lambda. 
 \]
\end{n}

\ssn{Example} 
For the call centre example above, the expected number of calls in 12 seconds is one fifth the number expected in a minute.  So $\lambda = 2$. 
So, from the formula, 
 \begin{gather*} 
  \PP(X=0) = e^{-2} \approx 0.135335, \quad \PP(X=1) = 2 e^{-2} \approx 0.270671 ,  \\ 
   \PP(X=2) = 2 e^{-2} \approx 0.270671 , \quad 
   \PP(X=3) = \frac43 e^{-2} \approx 0.180447
 \end{gather*} 
Then adding these and subtracting from one we get $\PP(X\geq 4) \approx 0.142876$. 
\end{n}


\ssn{Example} 
We could also use the Poisson distribution to approximate the Binomial distribution where $n$ is large and $p$ small.  For example, we could ask what the probability is of 5 treble-6 in 1000 tosses of three D6. The exact binomial answer is 
 \[
    \PP (X=5) = \binom{1000}{5} \left(\frac{215}{216}\right)^{995} \left(\frac1{216} \right)^5 \approx 0.17337.
 \]
The expected value here is ``$np$'' is $1000/216$ and number of occurrences is $5$.  So the Poisson approximation gives 
 \[
    e^{-1000/216}  \left(\frac{1000}{216} \right)^5 \frac 1{5!} \approx 0.17295.
 \]
\end{n}

\sse{}
Assume that dust particles drift around at random within some large volume.  The density of dust particles is $10^7$ per cubic metre.  I take a sample of 1cc volume.  What is the probability of their being $k$ dust particles in my sample? 
\end{e}

\sss
To start, $1cc$ is $10^{-6}$ cubic metres.  So the expected number of particles is $\lambda=10$.  Thus from Poisson:
\[
    \PP(X=k) = e^{-10} \frac{10^k}{k!}.
\]
So, for instance, the probability of exactly 10 particles is about 0.125 and the probability of none at all is about 0.0000454. 
\end{s}

\sse 
Studies in the 1990s concluded that computer memory suffered corruption because of a cosmic ray at a rate of one incident per 256Mb per month. On that basis, what is the approximate probability 2Gb of memory being corrupted by a cosmic ray twice in a day?  (Make the possibly unrealistic assumption that the probability is proportional to memory size.) 
\end{e}

\sss 
  Assuming 30 days per month, the expected number per day is $8/30$. We compute 1 minus the probability of zero and one strikes:
  \[
    1 - e^{-8/30} - e^{-8/30} \frac{8}{30} \approx 0.03. 
  \]
\end{s}

\sse 
In a situation where occurrences are modelled by a Poisson random variable, what is the expected time until the next occurrence? 
\end{e}

\sss 
Time to next occurrence is exponential with parameter $\lambda$ and so the expected time is $1/\lambda$. 
\end{s}

\sse 
Buses arrive at a bus stop randomly at an average rate of one every five minutes. I arrive at the bus stop. Assuming a Poisson distribution, find the probability that in the first 10 minutes no bus arrives, and then three arrive at once.   (Interpret ``three arrive at once'' to mean that in the next minute exactly three arrive.) 
\end{e}

\sss 
$0.0001477$. 
\end{s}



\ssn{Proposition}
Let $X_1$ and $X_2$ be independent Poisson random variables with parameters $\lambda_1, \lambda_2$ respectively. Then $X = X_1 + X_2$ is a Poisson random variable with parameter$\lambda = \lambda_1 + \lambda_2$. 

\begin{proof}
The pgfs for $X_1,X_2$ are $G_{X_1}(s)=e^{\lambda_1(s-1)}$ and $G_{X_2}(s)=e^{\lambda_2(s-1)}$. The pgf for the sum of independent RVs is the product of the generating functions and so the pgf of $X$ is $G_{X_1}(s)=e^{(\lambda_1+\lambda_2)(s-1)}$ which we recognise as the pgf of a Poisson RV\footnote{In the argument we are using the fact that the pgf determines the distribution. This is clear in the case of discrete RVs taking finitely many values but really needs further justification generally.} with parameter $\lambda_1 + \lambda_2$. 
\end{proof}
\end{n}

\ssn{Comment}
The property in the theorem is essential in the situations we are modelling. Suppose that $X_1$ and $X_2$ are Poisson RVs modelling the number of calls arriving at a call centre in two consecutive minutes. Then $X_1+X_2$ needs to model the number of calls arriving in the complete two minute period.  
\end{n}

\ssn{Relation with exponential distribution}
Consider a process like the arrival of calls at a call centre which we are modelling using a Poisson random variable assuming an average rate of $\mu$ per unit time. 

Starting at time $t=0$, the next call will arrive at some time $T$ which itself is a continuous random variable on $[0,\infty)$.   We can compute the pdf of $T$.   At time $t$ the expected number of calls to have occurred since $t=0$ is $\lambda = \mu t$. Thus we can use the Poisson distribution to compute 
 \[
   \PP( \text{No calls in [0,t]}) = e^{-\lambda} = e^{-\mu t}.
 \]
So the cdf of $T$ (i.e. the probability of a call having arrived during $[0,t)$ is $F_T(t) = 1 - e^{-\mu t}$ so 
 \[
 f_T(t) = F_T'(t) = \mu e^{-\mu t}.
  \]
 So from any base time, ``time to next occurrence'' is an exponential RV with parameter $\mu$. 
\end{n}

