

\ssn{The Gamma function} \label{guseful} 
The \emph{Gamma function} is a way of defining factorials for all positive real numbers rather than just integers. 
We define 
\tcb 
 \[
    \Gamma(z) = \int_0^\infty x^{z-1} e^{-x} \dd x, \quad \text{where $z>0$}.  
 \]
 \etcb 
\noindent 
Integrating by parts (where we differentiate the term $x^{z-1}$) we get 
 \begin{eqnarray*} 
  \Gamma(z)  &=& \int_0^\infty x^{z-1} e^{-x} \dd x \\
  &=& \left[ - x^{z-1} e^{-x}  \right]_0^\infty + 
    \int_0^\infty (z-1)x^{z-2} e^{-x} \dd x \\
    &=&  (z-1) \int_0^\infty x^{z-2} e^{-x} \dd x = 
     (z-1) \Gamma(z-1) 
 \end{eqnarray*} 
 So we see 
 \tcb
  \[
     \Gamma(z) = (z-1) \Gamma(z-1).
   \]
 \etcb 
 
 \noindent 
 Also, $\Gamma(1) = 1$ by an easy integral. So by the above, $\Gamma(2) = 1 . \Gamma(1) = 1$. And $\Gamma(3) = 2 \Gamma(2)=2$, and $\Gamma(4) = 3 \Gamma(3) = 6$. Carrying on, we see that for non-negative integers 
\tcb 
 \[
      \Gamma (n) = (n-1)! 
 \]
\etcb 
\noindent 
It is annoying that the definition of the gamma function is somehow ``off by one'' compared to the factorials, but we are stuck with it.    
\end{n}

\ssn{A useful formula} \label{guseful2} 
For $x, \lambda >0$ we have 
 \tcb 
 \[
      \int_0^\infty x^{z-1} e^{-\lambda x} \dd x = \frac{1}{\lambda^z}  \Gamma(z). 
 \]
 \etcb 
 \noindent 
This is derived by changing variables, substituting $u=\lambda x$ in the definition of the gamma function. 
\end{n} 

\ssn{Definition: The Gamma distribution}
Let $\alpha$ and $\lambda$ be positive constants. The random variable $X$ taking values in $[0,\infty)$ has a \ul{gamma distribution} and we write  $X \sim \gamm(\alpha, \lambda)$ if its pdf is  
\tcb 
 \[
    f_X(x) = \frac{\lambda^\alpha}{\Gamma(\alpha)} 
     x^{\alpha -1} e^{-\lambda x}. 
 \]
\etcb 
\noindent 
Note that when $\alpha = 1$ we have the exponential distribution that we studied earlier. 

The Gamma distribution is not a ``core'' distribution for us: we will use it for some examples, but familiarity with \emph{when} to use it is not expected. (But it is important: for example, the $\chi^2$ distribution with $v$ degrees of freedom used in statistics is $\gamm(v/2, 1/2)$.)  
\end{n} 

\ssn{Example} 
Compute $\EE(X)$ where $X \sim \gamm(z, \lambda)$.  The pdf for $X$ is thus 
 \[
   f_X(x) = \frac{\lambda^z}{\Gamma(z)} x^{z-1} e^{-\lambda x}. 
  \]
 So 
  \begin{eqnarray*} 
    \EE(X) &=& \int_0^\infty x f_X(x) \dd x \\  
    &=&  \frac{\lambda^z}{\Gamma(z)} \int_0^\infty x^z e^{-\lambda x} \dd x \\
    &=& \frac{\lambda^z}{\Gamma(z)} \frac{\Gamma(z+1)}{\lambda^{z+1}} \quad \text{(using the useful formula \S\ref{guseful2})} \\ 
  &=& \frac{z}{\lambda} \quad \text{(using final formula in \S\ref{guseful})}
  \end{eqnarray*} 

\end{n} 

\ssn{Useful and interesting integrals} 
The function $e^{-x^2}$ is fundamentally important in statistics particularly. Unfortunately there is no way of writing down its integral in terms of familiar functions.  One can however compute its integral over the whole real line by a trick. Let 
\[
    I = \int_{-\infty}^\infty e^{-x^2} \dd x.
\]
Then 
\begin{eqnarray*} 
    I^2 & = & \left(\int_{-\infty}^\infty e^{-x^2} \dd x\right) \, \left(\int_{-\infty}^\infty e^{-y^2} \dd y\right) \\
     &=& \int_{-\infty}^\infty \int_{-\infty}^\infty e^{-x^2}  e^{-y^2} \dd x \dd y  \\
     &=& \int_{r=0}^\infty \int_{\theta=0}^{2 \pi} e^{-r^2} r \dd \theta \dd r  \qquad\text{(converting to polar coordinates)}\\
     &=&   2 \pi \int_{r=0}^\infty e^{-r^2} r \dd r \\
     &=&  2 \pi \frac12 = \pi  
\end{eqnarray*} 
So 
\[
    \int_{-\infty}^\infty e^{-x^2} \dd x = \sqrt{\pi}
\]

Now consider $\Gamma(1/2)$.  It turns out we can do the integral by substituting $x = t^2$ as follows:
 \begin{eqnarray*} 
 \Gamma(1/2) & = & \int_0^\infty x^{-1/2} e^{-x} \dd x \\
  &=& \int_0^\infty t^{-1} e^{-t^2}  2 t \dd t \quad \text{(substituting)} \\
  &=&  \int_{-\infty}^\infty e^{-t^2}  \dd t \quad \text{(the integrand is even)} \\
  & = & \sqrt{\pi}.
\end{eqnarray*} 
And from $\Gamma(1/2) = \sqrt\pi$ we deduce that 
 \[
     \Gamma(3/2) = 1/2 \Gamma(1/2) = \frac{\sqrt\pi}2. 
 \]
So, if it makes sense to talk about factorials of things that are not integers, we arrive at 
 \[
      (-1/2)! \;\text{ ``$=$'' }\;  \sqrt\pi \qquad \text{and} \qquad (1/2)! \;\text{ ``$=$'' }\; \frac{\sqrt\pi}2. 
 \]
\end{n}


\ssp 
Following the analysis for the random variable $T$ which is the time, starting at $t=0$ of the arrival of the first call, show that the time $T_2$ of the arrival of the second call is a Gamma distribution. 
\end{e}
