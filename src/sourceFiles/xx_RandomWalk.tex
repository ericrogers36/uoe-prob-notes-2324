

\ssn{Sequences and recursion relations} 
We will need to work with sequences defined by what are known as ``difference equations'' or ``recursion relations''. For example, consider the sequence $x_k$ where 
 \[
      x_0 = 1, \quad x_{k+1} = 2 x_k  \quad\text{(for $k \geq 0$.)}
 \]
The sequence $x_0, x_1, x_2, \dots$ generated is $1,2,4,8,16,\dots$ and by inspecton a direct formula for the sequence is $x_k = 2^k$. 

We could also specify a sequence by a \emph{second order constant-coefficient difference equation} such as  
 \[
      x_{k+1} - 4 x_k + 3 a_{k-1} = 0, \quad x_0 = 0, \; x_1 = 1. 
 \]
Working out a couple of terms we discover $x_2 = 4, x_3 = 13$ and $x_4=30$. Because the equation determines a term from the two preceding ones, it requires us to have two ``initial values'' ($x_0$ and $x_1$) to determine the sequence. 

A way of solving such equations is to look for solutions of the form $x_k = \lambda^k$, where $\lambda$ is a constant to be determined.  Substituting in to the equation and cancelling $\lambda^{k-1}$ we discover $\lambda$ must satisfy the quadratic equation 
 \[
     \lambda^2 - 4 \lambda + 3 = (\lambda -1)(\lambda -3) = 0. 
 \]
(Notice the coefficients are the same as in the original equation.) 
If you substitute $x_k = 3^k$ back into the recurrence relation, you discover that it solves the equation (but not the initial conditions). Similarly $ x_k = 1^k = 1$ satisfies the equation. 

Because these equations are \emph{linear}, any linear combination of solutions is a solution. Thus for any constants $a,b$ we have that 
 \[
      x_k = a \, 1^k + b \, 3^k \; = \; a + b \, 3^k 
 \]
is a solution.  In fact, one can show that it is the general solution. 
We can thus solve our recurrence relation problem by using the initial conditions to fix $a$ and $b$.  

Substituting $k=0$ and $k=1$ in this case, we require 
 \[
       a+b = 0, \quad a + 3b = 1
 \]
which has the solution $a = -1/2$ and $b= 1/2$. Thus the sequence generated by our recursion relation and initial conditions is
 \[
     x_k  = \frac12 3^k - \frac12. 
 \]

This method even works if the quadratic that arises has complex roots (which is not something we are likely to need). The solutions that arise are always of the form $x_k = a \lambda_1^k + b \lambda_2^k$ where $\lambda_1, \lambda_2$ are te roots of the associated quadratic equation. 

There is however one special case.  It may be that the quadratic does not have two roots $\lambda_1, \, \lambda_2$ but has a single real, repeated root $\lambda$.  In that case, the general solution turns out to be 
 \[
        x_k = ( a k + b) \lambda^k. 
 \] 
\end{n} 

\sse{} 
  Solve 
  \[
     x_{k+1} - 5 x_k + 6 x_{k-1} = 0, \quad x_0 = 1, \; x_1 = 0.
  \]
 (You can check your answer by generating the first couple of terms by hand.) 
\end{e} 

\sss{} 
The roots of the quadratic are $2, 3$ and the solution is $x_k = 3 \, 2^k - 2 \, 3^k$.
\end{s} 

\sse{} 
  Solve 
  \[
     x_{k+1} - 4 x_k + 4 x_{k-1} = 0, \quad x_0 = 1, \; x_1 = 3.
  \]
 (This is the ``repeated root'' case. You can check your answer by generating the first couple of terms by hand.) 
\end{e} 

\sss{} 
The repeated root of the quadratic is  $\lambda = 2$ and the solution is $x_k =  ( (1/2) k + 1) 2^k$.
\end{s} 

\sse{} For amusement, solve 
  \[
     x_{k+1} - 2 x_k + 2 x_{k-1} = 0, \quad x_0 = 0, \; x_1 = 1.
  \]
 This is the ``complex roots'' case. The first few terms are 
  \[
    0, 1, 2, 2, 0, -4, -8, -8, 0, 16, 32, 32, 0, -64, -128, \dots
  \]
 Find the formula! 
\end{e} 

\sss{} 
The roots are $1 \pm i$ and the solution with these initial conditions is \[
     x_k = \frac{-i}{2} (1+i)^k + \frac{i}{2} (1-i)^k. 
\]
\end{s} 


\ssn{Random walks on $[0,n]$}
Consider a random walk on the set $[0,1,2,\ldots, n]$, meaning that one starts somewhere and then at each step independently moves one step to the right (i.e.\  from $k$ to $k+1$) with probability $p$ and to the left (i.e.\  from $k$ to $k-1$) with probability $1-p$.   The positions $0$ and $n$ are \ul{absorbing} meaning that when one reaches one of them you stop and the walk is finished.

Our first question is what is the probability starting from $k$ that one ends up being absorbed at $0$ rather than at $n$.  Let $x_k$ be that probability. Then conditioning on the first move we obtain the equation 
 \[
    x_{k} = p x_{k+1} + (1-p) x_{k-1} 
 \] 
or equivalently
  \[
     p x_{k+1} - x_k + (1-p) x_{k-1} = 0, \quad x_0=1, \; x_n=0
 \]  
where we have added boundary conditions saying that if we are at 0 then the probability of being absorbed at 0 is 1 and that if we are at n then the probability of being absorbed at 0 is 0. 

This 2nd order difference equation has associated polynomial 
 \[
      p \lambda^2 - \lambda + (1-p) = (p\lambda - (1-p))(\lambda -1) 
 \]
which provided $p \not=1/2$ has two roots: $\lambda = 1$ and $\lambda = q/p$ where $q=1-p$.   We discussed the case $p=1/2$ in lectures. 

So the general solution for $x_k$ is 
 \[
     x_k = a + b \left(\frac{q}{p}\right)^k 
 \]
Solving the two simultaneous equations (exercise) we get 
 \[
  \displaystyle     x_k = \frac{\left(\frac{q}{p}\right)^k - \left(\frac{q}{p}\right)^n }{1 - \left(\frac{q}{p}\right)^n}. 
 \]
 In the special case $p=1/2$ the result (from lectures) is 
  \[
             x_k = 1 - \frac{k}{n} 
  \]
\end{n}

\ssn{Wandering for ever} 
A question we have been avoiding is whether the random walk might in fact just wander forever in the interior and never reach either boundary.  In fact, clearly it can do that if e.g.\ it starts near the middle and alternates left and right moves.  So we have to ask how likely it is.  

If we reverse the boundary conditions so that we are computing the probability of being absorbed at $n$, we discover in both cases that the probability of absorption at $n$ is $1-x_k$ ans so the probability of wandering forever in the interior is zero. 
\end{n}

\sse
We could ask about the case where there is no right-hand limit (as we did in lectures for the case $p=1/2$ where we found $x_k=1$ for all $k$). 

Show that 
\[
     \lim_{n \map \infty} x_k = \begin{cases} 
         1 & \text{if} \;  p  < 1/2 \\ 
         \left( \frac{q}{p} \right)^k & \text{if} \;  p  > 1/2. 
     \end{cases}
\]
This suggests that this might be the solution of the ``no right endpoint'' case but does not prove it because it is not clear that the solution with no end point is equal to this limit.   But these answers are indeed correct. 
\end{e}


\sse{} 
Consider a random walk (equally likely to move in each direction) on the vertices of a regular $n$-gon. Choose two adjacent vertices.  Starting at one of the chosen vertices, what is the expected number of moves until you reach the other?   Try $n=3,4,5$ for a start.    
\end{e}
