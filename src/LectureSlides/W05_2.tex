\documentclass[11pt,pdf,ngerman,UKenglish]{beamer}%,handout
\usepackage[UKenglish]{babel}
\usepackage{array}
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
%%\usepackage{amsfonts}
%%\usepackage{amstext}
\usepackage{amsthm}
%\usepackage{stmaryrd}
\usepackage{relsize}
%\usepackage{graphics}
\usepackage{graphicx}
%\usepackage{mathptmx}
%\usepackage[scaled]{uarial}
\usepackage[T1]{fontenc}
%%\usepackage{a4wide}
\usepackage{makeidx}
\usepackage{textcomp}
\usepackage{ulem}
\usepackage{geometry}
%\usepackage{bbm}
\usepackage{tikz}
\usepackage{hyperref}
\usepackage{sverb}
\usepackage{caption}
\usepackage{listings}
\usepackage{tabularx, multirow}
%\usepackage{booktabs}
%\usepackage{txfonts}
%\usepackage[ansinew]{inputenc}
%\usepackage[latin1]{inputenc}
\usepackage{enumerate}
\usepackage{bbold}
\usepackage{dsfont}
\usepackage{listings}
\usepackage{xifthen}

\usepackage{tikz}
\usepackage{pgfplots}
\pgfplotsset{compat=1.11}
\usepackage{xcolor}
\usepackage{subfigure}

\usepackage{epsdice}


\lstset{
	language=Matlab,% choose the language of the code
	basicstyle=\footnotesize,% the size of the fonts that are used for the code
	numbers=left,% where to put the line-numbers
	numberstyle=\scriptsize,% the size of the fonts that are used for the line-numbers
	stepnumber=1,% the step between two line-numbers. If it's 1 each line will be numbered
	numbersep=5pt,% how far the line-numbers are from the code
	%backgroundcolor=\color{white},% choose the background color. You must add \usepackage{color}
	showspaces=false,% show spaces adding particular underscores
	showstringspaces=false,% underline spaces within strings
	showtabs=false,% show tabs within strings adding particular underscores
	%frame=single,% adds a frame around the code
	%tabsize=2,% sets default tabsize to 2 spaces
	captionpos=t,% sets the caption-position to bottom
	%caption=\lstname,
	breaklines=false,% sets automatic line breaking
	breakatwhitespace=false,% sets if automatic breaks should only happen at whitespace
	escapeinside={\%*}{*)}% if you want to add a comment within your code
}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\newcommand{\IR}{\mathds{R}}
%\newcommand{\IN}{{\mathbb{N}}}
\newcommand{\IN}{\mathds{N}}
\newcommand{\IZ}{{\mathbb{Z}}}
\newcommand{\IF}{{\mathbb{F}}}
\newcommand{\IK}{{\mathbb{K}}}
\newcommand{\IQ}{{\mathbb{Q}}}
\newcommand{\IC}{{\mathbb{C}}}
%\newcommand{\IP}{{\mathbb{P}}}
\newcommand{\IP}{\mathbb{P}}
\newcommand{\IE}{{\mathbb{E}}}
%\newcommand{\E}{\mbox{I\negthinspace E}}% Zeichen f√ºr den Erwartungswert
\newcommand{\E}{\mathds{E}}
\newcommand{\F}{\mathcal{F}}
\renewcommand{\S}{\mathcal{S}}

\newcommand{\de}{\delta}
\newcommand{\vol}{\operatorname{vol}}
\newcommand{\sk}{{\,|\,}}
\newcommand{\arccot}{\operatorname{arccot}}
\newcommand{\1}{\mathbb{1}}
\newcommand{\supp}{\operatorname{supp}}
\renewcommand{\phi}{\varphi}
\renewcommand{\epsilon}{\varepsilon}
\renewcommand{\Re}{\operatorname{Re}}
\newcommand{\aeq}{\Leftrightarrow}
%\newcommand{\M}{\widetilde{\text{M}}}
\newcommand{\erfc}{\operatorname{Erfc}}
\newcommand{\erf}{\operatorname{Erf}}
\newcommand{\qvar}[2]{\langle #1 , #1 \rangle _{#2}}
%\newcommand{\qvar}[2]{<\hspace{-1.5mm}#1\hspace{-0.3mm},\hspace{-0.5mm}#1\hspace{-1.5mm}>_{#2}}
\newcommand{\sign}{\operatorname{sign}}
\newcommand{\SEP}{\text{SEP}}
\newcommand{\M}{\mathcal{M}}
\newcommand{\conv}{\operatorname{conv}}

\newcommand{\Law}{\text{Law}}
 
\renewcommand{\qedsymbol}{$\blacksquare$}


\newcommand*{\cA}{\mathcal{A}}
\newcommand*{\cB}{\mathcal{B}}
\newcommand*{\cC}{\mathcal{C}}
\newcommand*{\cD}{\mathcal{D}}
\newcommand*{\cE}{\mathcal{E}}
\newcommand*{\cF}{\mathcal{F}}
\newcommand*{\cG}{\mathcal{G}}
\newcommand*{\cH}{\mathcal{H}}
\newcommand*{\cI}{\mathcal{I}}
\newcommand*{\cJ}{\mathcal{J}}
\newcommand*{\cK}{\mathcal{K}}
\newcommand*{\cL}{\mathcal{L}}
\newcommand*{\cM}{\mathcal{M}}
\newcommand*{\cN}{\mathcal{N}}
\newcommand*{\cO}{\mathcal{O}}
\newcommand*{\cP}{\mathcal{P}}
\newcommand*{\cQ}{\mathcal{Q}}
\newcommand*{\cR}{\mathcal{R}}
\newcommand*{\cS}{\mathcal{S}}
\newcommand*{\cT}{\mathcal{T}}
\newcommand*{\cU}{\mathcal{U}}
\newcommand*{\cX}{\mathcal{X}}
\newcommand*{\cY}{\mathcal{Y}}

\newcommand{\Var}{\operatorname{Var}}
\newcommand{\var}{\operatorname{Var}}

\newcommand{\myitem}{$\bullet$\hspace*{-3mm}}

\newcommand{\Ito}{It\^o\ }
\newcommand{\Itos}{It\^o's\ }


\newtheoremstyle{thm}% name
{10pt}% Space above
{18pt}% Space below 
{\itshape}% Body font
{}% Indent amount: Indent amount: empty = no indent, \parindent = normal paragraph indent
{\bf}% Theorem head font
{}% Punctuation after theorem head
{\newline }% Space after theorem head: { } = normal interword space; \newline = linebreak
{}% Theorem head spec (can be left empty, meaning `normal')

\newtheoremstyle{def}% name
{10pt}% Space above
{18pt}% Space below 
{}% Body font
{}% Indent amount: Indent amount: empty = no indent, \parindent = normal paragraph indent
{\bf}% Theorem head font
{}% Punctuation after theorem head
{\newline }% Space after theorem head: { } = normal interword space; \newline = linebreak
{}% Theorem head spec (can be left empty, meaning `normal')


\theoremstyle{thm}

%\newtheorem{theorem}{Theorem}[section]
%\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}

\newtheorem{assumption}[theorem]{Assumption}
\newtheorem{algorithm}[theorem]{Algorithm}

\theoremstyle{def}
%\newtheorem{definition}[theorem]{Definition}
%\newtheorem{example}[theorem]{Example}
%\newtheorem{remarks}[theorem]{Remark}

\renewenvironment{proof}{\par\noindent\textit{Proof.~}}{\hfill \qedsymbol\newline}

 
 
 
%\newtheorem{satz}{Satz}
%\newtheorem{theorem}{Theorem}%[section]
%\newtheorem{lemma}[theorem]{Lemma}
%\newtheorem{proposition}[theorem]{Proposition}
%\newtheorem{corollary}[theorem]{Corollary}
%\newtheorem{remarks}{Bemerkung}
%\newtheorem{definition}{Definition}
%\newtheorem{example}{Beispiel}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%Madrid %Singapore %Copenhagen %Warsaw
\mode<presentation>{\usetheme{Frankfurt}}

\title{Probability}
\author{Stefan Engelhardt}
\date{19th October 2023}%{\today}%{25st Jannuary 2022}
%\logo{...}

\setbeamercovered{transparent}

\begin{document}

\begin{frame}
\titlepage
\end{frame}
% Remove logo from the next slides
\logo{}




%\begin{frame}{Definition of Expectation}
%\vspace*{-2mm}
%\begin{block}{Definition: Expectation}
%If $X$ is a discrete rv:
%$$ \IE [ g(X) ] := \sum_{x_i} g(x_i) \cdot \IP( X = x_i)$$
%\ \\
%If $X$ is a continuous rv:
%$$ \IE [ g(X) ] := \int_{-\infty}^\infty g(x) \cdot f_X(x) dx.$$
%\end{block}
%\
%
%E.g.\ $g(x)=x$ $\to$ $\IE[X] = \int_\IR x \cdot f_X(x) dx$
%\\
%or $g(x) = x^2$ $\to$ $\IE[X^2] = \int_\IR x^2 \cdot f_X(x) dx.$
%\end{frame}
%
%
%\begin{frame}{Expectations are linear}
%\begin{block}{Theorem: Linearity of Expectation}
%Let $(X_i)$ be random variables and $(a_i)$, $b$ be constants. Then
%\begin{align*}
%\IE\left[ b + \sum_i a_i X_i \right] = b+ \sum_i a_i \IE[ X_i]
%.
%\end{align*}
%\end{block}
%\pause
%\textit{Example:} Roulette has the numbers from $1$ to $36$ in red (for odd) and black (for even). Additionally, there is the green $0$ and depending on how much they want to scam you, also a green $00$ and even $000$. The expected pay-off of each possible bet is $\frac{36}{n}$, where $n= 36 +$'greens', i.e.\ $n=37$ in standard roulette and $38$ in American roulette.
%\pause
%Due to linearity of expectations and us only being able to place bets $X_i$ with a non-negative value $a_i$, we get
%\begin{align*}
%\IE\left[ \sum_i a_i X_i \right] = \sum_i a_i \IE[X_i] = \sum a_i \cdot \frac{36}{n}
%= \frac{36}{n} \sum a_i < \sum a_i .
%\end{align*}
%\end{frame}
%
%
%\begin{frame}{Conditional Expectation}
%\begin{block}{Definition: Conditional Expectation}
%Let $X$ be a discrete random variable taking the values $(x_i)$. For an event $A$ with $\IP(A) >0$ we define the conditional expectation $\IE[ X \vert A ]$ by
%\begin{align*}
%\IE[ X \vert A] = \sum_{x_i} x_i \cdot \IP(X= x_i \vert A).
%\end{align*}
%\end{block}
%
%\begin{block}{The Law of Total Probability for Expectations}
%Let $X$ be a (discrete) random variable and $(A_i)_{i \in \{1, \ldots, n\}}$ a partition of $\Omega$, i.e.\ they are disjoint and $\bigsqcup_{i=1}^n A_i = \Omega$. Then
%\begin{align*}
%\IE[ X ] = \sum_{i=1}^n \IE[ X \vert A_i] \IP(A_i).
%\end{align*}
%\end{block}
%\end{frame}
%
%
%\begin{frame}{Conditional Expectation}
%\begin{block}{The Law of Total Probability for Expectations}
%Let $X$ be a (discrete) random variable and $(A_i)_{i \in \{1, \ldots, n\}}$ a partition of $\Omega$, i.e.\ they are disjoint and $\bigsqcup_{i=1}^n A_i = \Omega$. Then
%\begin{align*}
%\IE[ X ] = \sum_{i=1}^n \IE[ X \vert A_i] \IP(A_i).
%\end{align*}
%\end{block}
%\begin{proof}
%\begin{align*}
%\IE[X]
%\ & = \  \sum_{x_j} x_j \IP(X=x_j)
%%\\&
%\quad = \quad \sum_{x_j} x_j \sum_{i=1}^n \IP( X=x_j \vert A_i ) \IP( A_i)
%\\ &
%= \ \sum_{i=1}^n \sum_{x_j} x_j \IP( X=x_j \vert A_i ) \IP( A_i)
%%\\&
%\quad = \quad \sum_{i=1}^n \IE[ X \vert A_i] \IP(A_i)
%\end{align*}
%\end{proof}
%\end{frame}


\begin{frame}{Variance}
%\begin{block}{Definition: Variance}
%For a random variable $X$ with finite expectation we define its variance by
%\begin{align*}
%\Var (X) := \IE\left[ \left( X - \IE[X] \right)^2 \right].
%\end{align*}
%\end{block}
\begin{block}{Lemma}
Let $X$ be a rv with finite expectation. Then
\begin{align*}
\Var(X) := \IE\left[ \left( X - \IE[X] \right)^2 \right]
\ = \ \IE\left[ X^2 \right] - (\IE[X])^2.
\end{align*}
\end{block}
\begin{block}{Definition: Standard Deviation}
For a rv $X$ with finite variance, we call $\sqrt{ \var(X)}$ the standard deviation.
\end{block}
\begin{block}{Proposition}
Let $X$ be a rv with finite variance and $a,b\in \IR$ be constants. Then
\begin{align*}
\Var(aX+b) = a^2 \Var(X).
\end{align*}
\end{block}
\end{frame}


\begin{frame}{Independence}
\begin{block}{Definition: Independence of Random Variables}
Two random variables $X$ and $Y$ are independent if for all "nice" sets $A,B$
$$ \IP( X \in A, Y \in B) = \IP(X \in A) \cdot \IP(Y \in B).$$
\end{block}
\
\begin{block}{Lemma}
Let $X$ and $Y$ be two random variables. In the discrete and continuous case they are independent if and only if
\begin{itemize}
\item $X,Y$ are discrete: $\IP(X=x,Y=y) = \IP(X=x) \cdot \IP(Y=y)$% or $p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)$
\item $X,Y$ are continuous: $f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)$
\end{itemize}
for all $x,y\in \IR$.
\end{block}
\vfill
\end{frame}


\begin{frame}{Independent Product}
Reminder: $X,Y$ are independent, then for all $x,y$
\begin{itemize}
\item $X,Y$ are discrete: $\IP(X=x,Y=y) = \IP(X=x) \cdot \IP(Y=y)$% or $p_{X,Y}(x,y) = p_X(x) \cdot p_Y(y)$
\item $X,Y$ are continuous: $f_{X,Y}(x,y) = f_X(x) \cdot f_Y(y)$.
\end{itemize}
\ \\ \
\begin{lemma}
Let $X$ and $Y$ be two independent random variables. Then
\begin{align*}
\IE [ X \cdot Y ] = \IE[X] \cdot \IE [ Y ].
\end{align*}
\end{lemma}
\
\pause
\begin{block}{Important to remember}
$X,Y$ are independent $\Rightarrow$ $\IE [ X \cdot Y ] = \IE[X] \cdot \IE [ Y ]$
\\ \vspace*{1mm}
$\IE [ X \cdot Y ] = \IE[X] \cdot \IE [ Y ]$ $\nRightarrow$ $X,Y$ are independent.
\end{block}
\vfill
\end{frame}


\begin{frame}{Variance of Sums}
\begin{block}{Proposition}
Let $X$ and $Y$ independent random variables with finite variance. Then
\begin{align*}
\Var(X+Y) = \Var(X) + \Var(Y).
\end{align*}
\end{block}
\
\pause

\textit{Example:} Let $X_i$, $i\in \{1,\ldots,n\}$ be independent $Bernoulli(p)$ rv's.
\\ Now define $Y:= \sum_{i=1}^n X_i$. We know that by this definition $Y \sim Bin(n,p)$. 
\\ \pause Note that $\Var(X_i) = \IE[ X_i^2] - (\IE[X])^2 = p - p^2 = p(1-p)$. By the proposition above we also get that 
$$\Var(Y) = \Var \left( \sum_{i=1}^n X_i \right) = \sum_{i=1}^n \Var(X_i) = n p (1-p).$$
\end{frame}


\begin{frame}{Rules for calculating}
\begin{block}{}
Let $X$ and $Y$ be two random variables with finite variance and $a,b \in \IR$. Then
\begin{align*}
\Var(X) &= \IE[X^2] - (\IE[X])^2
\\
\IE[ a X + Y + b] &= a \IE[X] + \IE[Y] + b,
\\
\Var( a X + b) &= a^2 \Var(X)
\end{align*}
and if $X$ and $Y$ are independent, then
\begin{align*}
\Var(aX + bV)= a^2 \Var(X) + b^2 \Var(Y).
\end{align*}
\end{block}
\ \\
\pause
\textit{Example:} Let $X,Y$ be iid (independent, identically distributed) rv's. What is $\Var(X + X)$ and $\Var(X-Y)$?
\end{frame}


\begin{frame}{Some more Variances}
\begin{itemize}
\item $X \sim Geom(p)$ \pause $\to$ $\Var(X) = \frac{1-p}{p^2}$
\\ \
\item $X \sim Exp(\lambda)$ \pause $\to$ $\IE[X]=\frac1\lambda$, $\IE[X^2] = \frac{2}{\lambda^2}$ giving $\Var(X) = \frac{1}{\lambda^2}$
\\ \
\item $X \sim U([a,b])$ \pause $\to$ $\Var(X)= \frac{1}{12} (b-a)^2$
\\ \
\item $X \sim Poisson(\lambda)$ \pause $\to$ $\Var(X) = \lambda$
\end{itemize}
\end{frame}


\begin{frame}{Expectation and Variance of Averages}
Let $(X_i)$ be iid rv's with $\IE[X_i]=\mu \in \IR$ and $\Var(X_i)=\sigma^2 >0$. What is the expectation and variance of their average?
\\ $Y := \frac1n \sum_{i=1}^n X_i$.
\pause
\begin{align*}
\IE[Y] &= \IE \left[ \frac1n \sum_{i=1}^n X_i \right] = \frac{1}{n} \sum_{i=1}^n \mu = \mu
\\ 
\Var(Y) &= \Var \left( \frac1n \sum_{i=1}^n X_i \right) = \pause \frac{1}{n^2} \sum_{i=1}^n \Var(X_i) = \frac{1}{n} \sigma^2
\end{align*}
Hence, for $n \to \infty$ we have $\IE[Y] = \mu$ while $\Var(Y) \to 0$.
\\ \ \\ \pause
Let $Z:= h(h) \cdot \sum_{i=1}^n$. How to choose $h$ such that \\ $\Var(Z) \to \sigma^2$ for $n\to\infty$?
\vfill
\end{frame}


%\begin{frame}
%
%\end{frame}

\end{document}
